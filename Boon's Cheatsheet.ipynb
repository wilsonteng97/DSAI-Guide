{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn - for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Classification Tree\n",
    "# Import Decision Tree Classifier model from Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Import export_graphviz from sklearn.tree\n",
    "from sklearn.tree import export_graphviz\n",
    "# Import Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Render using graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "quizdata = pd.read_csv('file_name')\n",
    "# Extract columns - UniVariate Stats\n",
    "column1 = pd.DataFrame(quizdata['Column1'])\n",
    "column2 = pd.DataFrame(quizdata['Column2'])\n",
    "...\n",
    "# Extract only the numeric data variables - MultiVariate Stats\n",
    "numDF = pd.DataFrame(quizdata[[\"Column1\", \"Column2\", \"Column3\"]])\n",
    "\n",
    "# Access rows\n",
    "df.iloc[row]\n",
    "# Overall statistical description of the data and plot standard statistical distributions for each variable\n",
    "quizdata.head()\n",
    "print(quizdata.dtypes)\n",
    "print(\"Data type : \", type(quizdata))\n",
    "print(\"Data dims : \", quizdata.shape)\n",
    "quizdata.describe() #.head() or .round()\n",
    "quizdata.info()\n",
    "# Plots\n",
    "\n",
    "# Set up matplotlib figure with three subplots\n",
    "f, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
    "\n",
    "# Plot the basic uni-variate figures for HP\n",
    "sb.boxplot(df1, orient = \"h\", ax = axes[0,0])\n",
    "sb.distplot(df1, kde = False, ax = axes[0,1])\n",
    "sb.violinplot(df1, ax = axes[0,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for Attack\n",
    "sb.boxplot(df2, orient = \"h\", ax = axes[1,0], color = 'g')\n",
    "sb.distplot(df2, kde = False, ax = axes[1,1], color = 'g')\n",
    "sb.violinplot(df2, ax = axes[1,2], color = 'g')\n",
    "#set kde=True for Normal Distribution Curve\n",
    "#change name of dfs\n",
    "#change color\n",
    "#change axes\n",
    "\n",
    "# Draw the Boxplots of all variables\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.boxplot(data = numDF, orient = \"h\")\n",
    "\n",
    "# Draw the distributions of all variables\n",
    "f, axes = plt.subplots(6, 2, figsize=(12, 24))\n",
    "\n",
    "count = 0\n",
    "for var in numDF:\n",
    "    sb.distplot(numDF[var], ax = axes[count,0])\n",
    "    sb.violinplot(numDF[var], ax = axes[count,1])\n",
    "    count += 1\n",
    "\n",
    "# Jointplot\n",
    "sb.jointplot(x = df1, y = df2, height = 8)\n",
    "\n",
    "# Draw pairs of variables against one another - MultiVariate Stats\n",
    "sb.pairplot(data = numDF)\n",
    "\n",
    "# Catplot\n",
    "sb.catplot(y = \"Generation\", data = quizdata, kind = \"count\")\n",
    "\n",
    "# Create a joint dataframe by concatenating Total and Legendary\n",
    "jointDF = pd.concat([total_train, legnd_train], axis = 1, join_axes = [total_train.index])\n",
    "\n",
    "## Joint Boxplot of Total Train against Legendary Train\n",
    "f, axes = plt.subplots(1, 1, figsize=(18, 6))\n",
    "sb.boxplot(x = \"Total\", y = \"Legendary\", data = jointDF, orient = \"h\")\n",
    "## Joint Swarmplot of Total Train against Legendary Train\n",
    "f, axes = plt.subplots(1, 1, figsize=(18, 6))\n",
    "sb.swarmplot(x = \"Total\", y = \"Legendary\", data = jointDF, orient = \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for unique data\n",
    "# Generations in the Dataset\n",
    "print(\"Number of Generations :\", len(quizdata[\"Generation\"].unique()))\n",
    "\n",
    "# Pokemons in each Generation\n",
    "print(quizdata[\"Generation\"].value_counts())\n",
    "sb.catplot(y = \"Generation\", data = quizdata, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a joint dataframe by concatenating the two variables\n",
    "jointDF = pd.concat([df1, df2], axis = 1, join_axes = [df1.index])\n",
    "\n",
    "# Calculate the correlation between the two columns/variables\n",
    "jointDF.corr()\n",
    "\n",
    "# Heatmap - UniVariate Stats\n",
    "sb.heatmap(jointDF.corr(), vmin = -1, vmax = 1, annot = True, fmt=\".2f\")\n",
    "\n",
    "# Heatmap of the Correlation Matrix - MultiVariate Stats\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "sb.heatmap(numDF.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Tree\n",
    "\n",
    "#PRICE against HEIGHT\n",
    "X_train, X_test, y_train, y_test = train_test_split(CHANGE THIS UNIVARIATE, FIX THIS UNIVARIATE USU CATEGORY, test_size = CHANGE THIS)\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", X_train.shape)\n",
    "print(\"Test Set  :\", X_test.shape)\n",
    "\n",
    "# Train the Decision Tree Classifier model to fit Price and Height\n",
    "dectree = DecisionTreeClassifier(max_depth = CHANGE THIS)\n",
    "dectree.fit(X_train, y_train)\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Decision Tree\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = X_train.columns,              # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression object\n",
    "linreg = LinearRegression()\n",
    "# Train the Linear Regression model\n",
    "linreg.fit(hp_train, total_train)\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients \\t: a = ', linreg.coef_)\n",
    "\n",
    "# Formula for the Regression line\n",
    "regline_x = hp_train\n",
    "regline_y = linreg.intercept_ + linreg.coef_ * hp_train\n",
    "\n",
    "# Plot the Linear Regression line\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(hp_train, total_train)\n",
    "plt.plot(regline_x, regline_y, 'r-', linewidth = 3)\n",
    "plt.show()\n",
    "\n",
    "# Predict Total values corresponding to HP Train\n",
    "total_train_pred = linreg.predict(hp_train)\n",
    "\n",
    "# Plot the Linear Regression line\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(hp_train, total_train)\n",
    "plt.scatter(hp_train, total_train_pred, color = \"r\")\n",
    "plt.show()\n",
    "\n",
    "# Explained Variance (R^2)\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(hp_train, total_train))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "\n",
    "mse = mean_sq_err(total_train, total_train_pred)\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))\n",
    "\n",
    "# Predict Total values corresponding to HP Test\n",
    "total_test_pred = linreg.predict(hp_test)\n",
    "\n",
    "# Plot the Predictions\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(hp_test, total_test, color = \"green\")\n",
    "plt.scatter(hp_test, total_test_pred, color = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# MultiVariate Stats - set X to contain more than one 'Column'\n",
    "X = pd.DataFrame(pkmndata[[\"HP\", \"Attack\", \"Defense\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
