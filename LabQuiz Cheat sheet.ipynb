{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt \n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tree Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data / making a DataFrame\n",
    "# variable naame = pd.read_\n",
    "\n",
    "#CSV files\n",
    "pkmndata = pd.read_csv('pokemonData.csv')\n",
    "traindata = pd.read_csv(r'C:\\Users\\MARC0051\\Desktop\\Cx1015\\train.csv')\n",
    "\n",
    "#Type and dimensions(shape)\n",
    "print(\"Data type : \", type(csv_data))\n",
    "print(\"Data dims : \", csv_data.shape)\n",
    "\n",
    "#txt files\n",
    "txt_data = pd.read_table('data/somedata.txt', sep = \"\\s+\", header = None)\n",
    "\n",
    "#Type and dimensions(shape)\n",
    "print(\"Data type : \", type(txt_data))\n",
    "print(\"Data dims : \", txt_data.shape)\n",
    "\n",
    "#XLS files\n",
    "xls_data = pd.read_excel('data/somedata.xlsx', sheet_name = 'Sheet1', header = None)\n",
    "\n",
    "#Type and dimensions(shape)\n",
    "print(\"Data type : \", type(xls_data))\n",
    "print(\"Data dims : \", xls_data.shape)\n",
    "\n",
    "#JSON files\n",
    "json_data = pd.read_json('data/somedata.json')\n",
    "\n",
    "#Type and dimensions(shape)\n",
    "print(\"Data type : \", type(json_data))\n",
    "print(\"Data dims : \", json_data.shape)\n",
    "\n",
    "#HTML\n",
    "html_data = pd.read_html('http://www.imdb.com/title/tt0441773/fullcredits/?ref_=tt_ov_st_sm')\n",
    "\n",
    "#Type and printing tables\n",
    "print(\"Data type : \", type(html_data))\n",
    "print(\"HTML tables : \", len(html_data))\n",
    "html_data[2].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking variables and their datatypes and information about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check variables and their datatypes\n",
    "print(pkmndata.dtypes)\n",
    "\n",
    "# Information about the Variables\n",
    "pkmndata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Single Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = pd.DataFrame(pkmndata['HP']) #Extracting the variable and its data by creating a new dataframe\n",
    "print(\"Data type : \", type(hp))   #Print data type and shape.\n",
    "print(\"Data dims : \", hp.size)\n",
    "\n",
    "#Changing 1st row to heading\n",
    "medalData.columns = medalData.iloc[0]   # copy first row to column names\n",
    "medalData = medalData.drop(0)           # drop the first row (redundant)\n",
    "\n",
    "#Extracting certain data types (e.g. int64)\n",
    "houseDataNum = houseData.loc[:, houseData.dtypes == np.int64]\n",
    "#or\n",
    "houseDataNum = houseData.select_dtypes(include = np.int64)\n",
    "\n",
    "#To drop/remove certain variables from a dataframe\n",
    "houseDataNum = houseDataNum.drop(['MSSubClass','OverallQual','OverallCond','YearBuilt','YearRemodAdd','MoSold','YrSold'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data types to other data types\n",
    "use .astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseCatData['MSSubClass'] = houseCatData['MSSubClass'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uni Variate Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.describe()                    #Check the summary statistics of a uni-variate series\n",
    "                                 #Only for numerical values, not categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(24, 4))\n",
    "sb.boxplot(hp, orient = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.distplot(hp, kde = False, color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Density Estimate(KDE) without histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.distplot(hp, hist = False, color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram with Kernel Density Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.distplot(hp, color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violin plot (Combines both KDE and boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.violinplot(hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniVariate Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create new dataframes for variables\n",
    "total = pd.DataFrame(pkmndata['Total'])  # Response\n",
    "hp = pd.DataFrame(pkmndata['HP'])        # Predictor\n",
    "\n",
    "#Not random samples, partition data set\n",
    "# Train Set : 600 samples\n",
    "hp_train = pd.DataFrame(hp[:600])\n",
    "total_train = pd.DataFrame(total[:600])\n",
    "\n",
    "# Test Set : 200 samples\n",
    "hp_test = pd.DataFrame(hp[-200:])\n",
    "total_test = pd.DataFrame(total[-200:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression model from Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression object\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model.\n",
    "Train to fit the equation y=ax+b\n",
    "linreg.fit(x,y) -> x is the predictor y is the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Linear Regression model\n",
    "linreg.fit(x, y)\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients \\t: a = ', linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the regression line based on coefficitnet-intercept form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula for the Regression line, y=ax+b\n",
    "regline_x = x_train\n",
    "regline_y = linreg.intercept_ + linreg.coef_ * x_train\n",
    "\n",
    "# Plot the Linear Regression line\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(regline_x, regline_y, 'r-', linewidth = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the regression line based on predcition using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Total values corresponding to HP Train\n",
    "y_train_pred = linreg.predict(x_train)\n",
    "\n",
    "# Plot the Linear Regression line\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.scatter(x_train, y_train_pred, color = \"r\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodness to fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d71ec4cb1609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Explained Variance (R^2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Explained Variance (R^2) \\t:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Mean Squared Error (MSE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean_sq_err\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linreg' is not defined"
     ]
    }
   ],
   "source": [
    "# Explained Variance (R^2)\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(hp_train, total_train))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "\n",
    "mse = mean_sq_err(total_train, total_train_pred)\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression using random train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall the Total-HP Dataset\n",
    "total = pd.DataFrame(pkmndata['Total'])   # Response\n",
    "hp = pd.DataFrame(pkmndata['HP'])         # Predictor\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(hp, total, test_size = 0.25)\n",
    "\n",
    "# Linear Regression using Train Data\n",
    "linreg = LinearRegression()         # create the linear regression object\n",
    "linreg.fit(X_train, y_train)        # train the linear regression model\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept of Regression \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients of Regression \\t: a = ', linreg.coef_)\n",
    "print()\n",
    "\n",
    "# Predict Total values corresponding to HP\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-variate statistics (2 variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up 2 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = pd.DataFrame(pkmndata['HP'])\n",
    "attack = pd.DataFrame(pkmndata['Attack'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising uni-variate data independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib figure with three subplots\n",
    "f, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
    "\n",
    "# Plot the basic uni-variate figures for HP\n",
    "sb.boxplot(hp, orient = \"h\", ax = axes[0,0])\n",
    "sb.distplot(hp, kde = False, ax = axes[0,1])\n",
    "sb.violinplot(hp, ax = axes[0,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for Attack\n",
    "sb.boxplot(attack, orient = \"h\", ax = axes[1,0], color = 'g')\n",
    "sb.distplot(attack, kde = False, ax = axes[1,1], color = 'g')\n",
    "sb.violinplot(attack, ax = axes[1,2], color = 'g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-variate boxplot\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "sb.boxplot(x = 'MSSubClass', y = 'SalePrice', data = houseCatSale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JointPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(x = attack, y = hp, height = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a joint dataframe by concatenating the two variables\n",
    "jointDF = pd.concat([x, y], axis = 1, join_axes = [x.index])\n",
    "jointDF.corr()         # Calculate the correlation between the two columns/variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(jointDF.corr(), vmin = -1, vmax = 1, annot = True, fmt=\".2f\")\n",
    "\n",
    "# OR\n",
    "f, axes = plt.subplots(1, 1, figsize=(20, 8))\n",
    "sb.heatmap(houseCatData.groupby(['BldgType', 'MSSubClass']).size().unstack(), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Variate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the numeric data variables\n",
    "numDF = pd.DataFrame(pkmndata[[\"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiVariate boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Boxplots of all variables\n",
    "f, axes = plt.subplots(1, 1, figsize=(24, 12))\n",
    "sb.boxplot(data = numDF, orient = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate violin and histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the distributions of all variables\n",
    "f, axes = plt.subplots(6, 2, figsize=(12, 24))\n",
    "\n",
    "count = 0\n",
    "for var in numDF:\n",
    "    sb.distplot(numDF[var], ax = axes[count,0])\n",
    "    sb.violinplot(numDF[var], ax = axes[count,1])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate boxplot, distplot, violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the distributions of all variables\n",
    "f, axes = plt.subplots(6, 3, figsize=(18, 24))\n",
    "colors = [\"r\", \"g\", \"b\", \"m\", \"c\", \"y\"]\n",
    "\n",
    "count = 0\n",
    "for var in numeric_data:\n",
    "    sb.boxplot(numeric_data[var], orient = \"h\", color = colors[count], ax = axes[count,0])\n",
    "    sb.distplot(numeric_data[var], color = colors[count], ax = axes[count,1])\n",
    "    sb.violinplot(numeric_data[var], color = colors[count], ax = axes[count,2])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate correlation matrix and heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the complete  correlation matrix\n",
    "numDF.corr()\n",
    "\n",
    "# Heatmap of the Correlation Matrix\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "sb.heatmap(houseNumData.corr(), vmin = -1, vmax = 1, linewidths = 1,\n",
    "           annot = True, fmt = \".2f\", annot_kws = {\"size\": 18}, cmap = \"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pairs of variables against one another\n",
    "sb.pairplot(data = numDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cat Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single variable catplot\n",
    "sb.catplot(y = \"Type 1\", data = pkmndata, kind = \"count\", height = 8)\n",
    "\n",
    "#Multivariable catplot\n",
    "sb.catplot(y = 'Type 1', data = pkmndata, col = 'Generation', kind = 'count', col_wrap = 2, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint Swarm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a joint dataframe by concatenating Total and Legendary\n",
    "jointDF = pd.concat([total_train, legnd_train], axis = 1, join_axes = [total_train.index])\n",
    "\n",
    "# Joint Swarmplot of Total Train against Legendary Train\n",
    "f, axes = plt.subplots(1, 1, figsize=(18, 6))\n",
    "sb.swarmplot(x = \"Total\", y = \"Legendary\", data = jointDF, orient = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Variate linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Model : y =  洧녩1   칑  x1 +  洧녩2   칑  x2 +  洧녩3   칑  x3 +  洧녪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata[\"Total\"])\n",
    "X = pd.DataFrame(pkmndata[[\"HP\", \"Attack\", \"Defense\"]])\n",
    "\n",
    "# Setting up the regression problem with train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "print(\"Test Set  :\", y_test.shape, X_test.shape)\n",
    "\n",
    "# Import LinearRegression model from Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Linear Regression using Train Data\n",
    "linreg = LinearRegression()         # create the linear regression object\n",
    "linreg.fit(X_train, y_train)        # train the linear regression model\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept of Regression \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients of Regression \\t: a = ', linreg.coef_)\n",
    "print()\n",
    "\n",
    "# Print the Coefficients against Predictors\n",
    "pd.DataFrame(list(zip(X_train.columns, linreg.coef_[0])), columns = [\"Predictors\", \"Coefficients\"])\n",
    "\n",
    "# Predict the Total values from Predictors\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodness of fit of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using a regression model\n",
    "Once obtained a multivariate regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Extract Response and Predictors\n",
    "predictors = [\"HP\", \"Attack\", \"Defense\"]\n",
    "\n",
    "y = pd.DataFrame(pkmndata[\"Total\"])\n",
    "X = pd.DataFrame(pkmndata[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Linear Regression using Train Data\n",
    "linreg = LinearRegression()         # create the linear regression object\n",
    "linreg.fit(X_train, y_train)        # train the linear regression model\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept of Regression \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients of Regression \\t: a = ', linreg.coef_)\n",
    "print()\n",
    "\n",
    "# Print the Coefficients against Predictors\n",
    "print(pd.DataFrame(list(zip(X_train.columns, linreg.coef_[0])), columns = [\"Predictors\", \"Coefficients\"]))\n",
    "print()\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for Prediction\n",
    "pkmndata_pred = pkmndata[pkmndata[\"Name\"].isin([\"Charizard\", \"Snorlax\", \"Vivillon\"])]\n",
    "pkmndata_pred\n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(pkmndata_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred\n",
    "\n",
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = pkmndata_pred.index)\n",
    "pkmndata_acc = pd.concat([pkmndata_pred[[\"Name\", \"Total\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(pkmndata_acc[\"Total\"] - pkmndata_acc[\"PredTotal\"]) / pkmndata_acc[\"Total\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error\"], index = pkmndata_pred.index)\n",
    "pkmndata_acc = pd.concat([pkmndata_acc, y_errs], axis = 1)\n",
    "\n",
    "pkmndata_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution and deviation of errors in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train = mean_squared_error(y_train, y_train_pred)\n",
    "StdE_pred = np.sqrt(len(y_train) * MSE_train/(len(y_train) - 2))\n",
    "\n",
    "print(\"Mean Squared Error (MSE) \\t:\", MSE_train.round(2))\n",
    "print(\"Pred Standard Error (SE) \\t:\", StdE_pred.round(2))\n",
    "\n",
    "#In Prediction, we assume a Gaussian (Normal) Distribution for Predictions Errors.\n",
    "#The 95% Prediction Interval for any data point is given by 洧녞洧洧뉧롐놿롐뒳롐넗롐뫯롐뒳롐럻롐췀1.96칑洧녡洧노洧녬洧냦\n",
    "#The 99% Prediction Interval for any data point is given by  洧녞洧洧뉧롐놿롐뒳롐넗롐뫯롐뒳롐럻롐췀2.58칑洧녡洧노洧녬洧냦\n",
    "y_95l = pd.DataFrame(pkmndata_acc[\"PredTotal\"] - 1.96*StdE_pred).rename(columns = {\"PredTotal\" : \"95 Lower\"})\n",
    "y_95u = pd.DataFrame(pkmndata_acc[\"PredTotal\"] + 1.96*StdE_pred).rename(columns = {\"PredTotal\" : \"95 Upper\"})\n",
    "y_99l = pd.DataFrame(pkmndata_acc[\"PredTotal\"] - 2.58*StdE_pred).rename(columns = {\"PredTotal\" : \"99 Lower\"})\n",
    "y_99u = pd.DataFrame(pkmndata_acc[\"PredTotal\"] + 2.58*StdE_pred).rename(columns = {\"PredTotal\" : \"99 Upper\"})\n",
    "\n",
    "pkmndata_int = pd.concat([pkmndata_acc, y_95l, y_95u, y_99l, y_99u], axis = 1)\n",
    "pkmndata_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of unique data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique heading\n",
    "print(\"Number of Generations :\", len(pkmndata[\"Generation\"].unique()))\n",
    "\n",
    "# O/p: Unique Names of Pokemon : 800\n",
    "\n",
    "#Number of elements in each heading\n",
    "print(pkmndata[\"Generation\"].value_counts())\n",
    "\n",
    "# Check the Variable Information\n",
    "print(pkmndata_clean[\"TYPE_2\"].dropna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".isnull() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singletype_data = pkmndata[pkmndata[\"Type 2\"].isnull()]  #check if a variable is a null type\n",
    "dualtype_data = pkmndata[pkmndata[\"Type 2\"].isnull() == False]  #check if a variable is NOT a null type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Variable heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. make a new dataframe for the 2 variable\n",
    "dualtype_data = pkmndata[pkmndata[\"Type 2\"].isnull() == False]\n",
    "\n",
    "# Distribution of the Two Types\n",
    "f, axes = plt.subplots(1, 1, figsize=(20, 20))\n",
    "sb.heatmap(dualtype_data.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 18}, cmap = \"BuGn\")\n",
    "\n",
    "# Distribution of the Two Types over multiple variables.\n",
    "f, axes = plt.subplots(3, 2, figsize=(20, 30))\n",
    "\n",
    "dualtype_gen1 = dualtype_data[dualtype_data[\"Generation\"] == 1]\n",
    "dualtype_gen2 = dualtype_data[dualtype_data[\"Generation\"] == 2]\n",
    "dualtype_gen3 = dualtype_data[dualtype_data[\"Generation\"] == 3]\n",
    "dualtype_gen4 = dualtype_data[dualtype_data[\"Generation\"] == 4]\n",
    "dualtype_gen5 = dualtype_data[dualtype_data[\"Generation\"] == 5]\n",
    "dualtype_gen6 = dualtype_data[dualtype_data[\"Generation\"] == 6]\n",
    "\n",
    "sb.heatmap(dualtype_gen1.groupby(['Type 1', 'Type 2']).size().unstack(),\n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 14}, cmap = \"BuGn\", ax = axes[0,0])\n",
    "sb.heatmap(dualtype_gen2.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 14}, cmap = \"BuGn\", ax = axes[0,1])\n",
    "sb.heatmap(dualtype_gen3.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 14}, cmap = \"BuGn\", ax = axes[1,0])\n",
    "sb.heatmap(dualtype_gen4.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 14}, cmap = \"BuGn\", ax = axes[1,1])\n",
    "sb.heatmap(dualtype_gen5.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 14}, cmap = \"BuGn\", ax = axes[2,0])\n",
    "sb.heatmap(dualtype_gen6.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 14}, cmap = \"BuGn\", ax = axes[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dulplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Duplicate \n",
    "dupid_data = pkmndata[pkmndata.duplicated(\"#\", keep = False)]\n",
    "dupid_data.sort_values(by = \"Name\").head(n = 10)\n",
    "\n",
    "# Pokemons with Duplicate IDs\n",
    "print(\"Pokemons with Duplicate IDs :\", len(dupid_data))\n",
    "dupids = dupid_data[\"#\"].unique()\n",
    "print(\"Unique Pokemons with DupIDs :\", len(dupids))\n",
    "print()\n",
    "\n",
    "# Group Pokemons with same ID\n",
    "print(\"# \\t Count \\t List of Pokemons with Duplicate IDs\")\n",
    "print()\n",
    "for dupid in dupids:\n",
    "    dupid_list = list(dupid_data[dupid_data[\"#\"] == dupid][\"Name\"])\n",
    "    print(dupid, \"\\t\", len(dupid_list), \"\\t\", dupid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the Dataset\n",
    "pkmndata_clean = pkmndata.copy()\n",
    "\n",
    "# Rename \"#\" to \"ID\" of Pokemon\n",
    "pkmndata_clean.rename(columns = {'#': 'ID'}, inplace = True)\n",
    "\n",
    "# Convert all Variable Names to UPPERCASE\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.upper()\n",
    "\n",
    "# Remove all spaces and dots from Variable Names\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.replace(\".\",\"\")\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.replace(\" \",\"_\")\n",
    "\n",
    "# Print the Variable Information to check\n",
    "pkmndata_clean.info()\n",
    "\n",
    "# Fix the weird Names of Pokemons\n",
    "import re\n",
    "\n",
    "# Fix names with extra Extensions\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Forme)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Cloak)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Rotom)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Size)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(Hoopa)(.+)',r'\\2', x))\n",
    "\n",
    "# Fix names with Mega in between\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+Mega)(.+)',r'\\1', x))\n",
    "\n",
    "# Remove Blanks from all the Names\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'\\s+','', x))\n",
    "\n",
    "# Pokemons with Duplicate IDs\n",
    "dupid_data_clean = pkmndata_clean[pkmndata_clean.duplicated(\"ID\", keep = False)]\n",
    "print(\"Pokemons with Duplicate IDs :\", len(dupid_data_clean))\n",
    "dupids_clean = dupid_data_clean[\"ID\"].unique()\n",
    "print(\"Unique Pokemons with DupIDs :\", len(dupids_clean))\n",
    "print()\n",
    "\n",
    "# Group Pokemons with same ID\n",
    "print(\"# \\t Count \\t List of Pokemons with Duplicate IDs\")\n",
    "print()\n",
    "for dupid_clean in dupids_clean:\n",
    "    dupid_list_clean = list(dupid_data_clean[dupid_data_clean[\"ID\"] == dupid_clean][\"NAME\"])\n",
    "    print(dupid_clean, \"\\t\", len(dupid_list_clean), \"\\t\", dupid_list_clean)\n",
    "    \n",
    "# Fix the X,Y labels for Charizard and Mewtwo\n",
    "pkmndata_clean.loc[7,\"NAME\"] = \"CharizardMegaX\"\n",
    "pkmndata_clean.loc[8,\"NAME\"] = \"CharizardMegaY\"\n",
    "pkmndata_clean.loc[163,\"NAME\"] = \"MewtwoMegaX\"\n",
    "pkmndata_clean.loc[164,\"NAME\"] = \"MewtwoMegaY\"\n",
    "\n",
    "# Set NAME as the Index of the DataFrame\n",
    "pkmndata_clean = pkmndata_clean.set_index('NAME')\n",
    "\n",
    "# Print the DataFrame to check\n",
    "pkmndata_clean.sample(n = 10)\n",
    "\n",
    "# Check missing values in data\n",
    "pkmndata_clean.isnull().sum()\n",
    "\n",
    "# Fill missing values in data\n",
    "pkmndata_clean[\"TYPE_2\"].fillna(value = \"NoType\", inplace = True)\n",
    "\n",
    "# Check the Variable Information\n",
    "print(pkmndata_clean[\"TYPE_2\"].dropna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strongest Pokemons -- the Top 10\n",
    "pkmndata_clean.sort_values('TOTAL', ascending=False).head(10)\n",
    "\n",
    "# Weakest Pokemons -- the Bottom 10\n",
    "pkmndata_clean.sort_values('TOTAL', ascending=True).head(10)\n",
    "\n",
    "# Strongest Legendary Pokemons -- the Top 10\n",
    "pkmndata_clean[pkmndata_clean[\"LEGENDARY\"] == True].sort_values('TOTAL', ascending=False).head(10)\n",
    "\n",
    "# Strongest Pokemons in each Generation -- the Top 10\n",
    "generation = 1\n",
    "pkmndata_clean[pkmndata_clean[\"GENERATION\"] == generation].sort_values('TOTAL', ascending=False).head(10)\n",
    "\n",
    "# Compute the Average TOTAL across every pair of TYPEs\n",
    "total_means = pkmndata_clean.groupby(['TYPE_1', 'TYPE_2']).mean().loc[:, 'TOTAL']\n",
    "\n",
    "# Strongest Pokemons in each Pair of Types -- the Top 10\n",
    "print(total_means.reset_index().sort_values('TOTAL', ascending=False).head(10).round(2))\n",
    "\n",
    "# Heatmap of Average TOTAL across every pair of TYPEs\n",
    "f, axes = plt.subplots(1, 1, figsize=(20, 20))\n",
    "sb.heatmap(total_means.unstack(), linewidths = 1,\n",
    "           annot = True, fmt = \".0f\", annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decision Tree\n",
    "1. Set up response and predictor dataframes\n",
    "2. Divide data into train and test samples\n",
    "3. Import decision tree\n",
    "4. Train the tree\n",
    "5. Import graphviz from sklearn.tree \n",
    "6. Export the decision tree as a dot object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Decision Tree Classifier model from Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a Decision Tree Classifier object\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)\n",
    "\n",
    "# Train the Decision Tree Classifier model\n",
    "dectree.fit(total_train, legnd_train)\n",
    "\n",
    "# Import export_graphviz from sklearn.tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Export the Decision Tree as a dot object\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = total_train.columns,          # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "# Render using graphviz\n",
    "import graphviz\n",
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodness of fit of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Legendary corresponding to Total Train\n",
    "y_train_pred = dectree.predict(x_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(x_train, y_train))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})\n",
    "\n",
    "# Predict Legendary corresponding to Total Test\n",
    "y_test_pred = dectree.predict(x_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(x_test, y_test))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of classification tree using random train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Recall the Legendary-Total Dataset\n",
    "legnd = pd.DataFrame(pkmndata['Legendary'])   # Response\n",
    "total = pd.DataFrame(pkmndata['Total'])       # Predictor\n",
    "\n",
    "# Split the Legendary-Total Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(total, legnd, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Legendary values corresponding to Total\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "# Plot the Decision Tree\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = X_train.columns,              # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata['Legendary'])\n",
    "X = pd.DataFrame(pkmndata[[\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]]) \n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "# Plot the Decision Tree\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = X_train.columns,              # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Pokemons for Prediction\n",
    "pkmndata_pred = pkmndata[pkmndata[\"Name\"].isin([\"Mewtwo\", \"GiratinaOrigin Forme\", \"Butterfree\"])]\n",
    "pkmndata_pred\n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(pkmndata_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = dectree.predict(X_pred)\n",
    "y_pred\n",
    "\n",
    "# Summarize the Actuals and Predictions\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredLegend\"], index = pkmndata_pred.index)\n",
    "pkmndata_acc = pd.concat([pkmndata_pred[[\"Name\", \"Legendary\"]], y_pred], axis = 1)\n",
    "\n",
    "pkmndata_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking class probabilities along final class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Probabilities corresponding to Predictors\n",
    "y_prob = dectree.predict_proba(X_pred)\n",
    "y_prob\n",
    "\n",
    "# Summarize the Probabilities with the Predictions\n",
    "y_prob = pd.DataFrame(list(y_prob[:,1]), columns = [\"ProbLegend\"], index = pkmndata_pred.index)\n",
    "pkmndata_conf = pd.concat([pkmndata_acc, y_prob], axis = 1)\n",
    "\n",
    "pkmndata_conf\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclassification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Extract Response and Predictors\n",
    "predictors = [\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]\n",
    "\n",
    "y = pd.DataFrame(pkmndata['Type 1'].astype('category'))\n",
    "X = pd.DataFrame(pkmndata[predictors]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Draw the distribution of Response\n",
    "f, axes = plt.subplots(1, 1, figsize=(18, 8))\n",
    "sb.countplot(y_train[\"Type 1\"])\n",
    "\n",
    "# Relationship between Response and the Predictors\n",
    "trainDF = pd.concat([y_train, X_train], axis = 1, join_axes = [y_train.index])\n",
    "\n",
    "f, axes = plt.subplots(7, 1, figsize=(18, 42))\n",
    "\n",
    "count = 0\n",
    "for var in X_train:\n",
    "    sb.boxplot(x = var, y = \"Type 1\", data = trainDF, orient = \"h\", ax = axes[count])\n",
    "    count += 1\n",
    "    \n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 4)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(2, 1, figsize=(12, 24))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "# Plot the Decision Tree\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = X_train.columns,              # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data for Prediction\n",
    "pkmndata_pred = pkmndata[pkmndata[\"Name\"].isin([\"Mewtwo\", \"GiratinaOrigin Forme\", \"Butterfree\"])]\n",
    "pkmndata_pred\n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(pkmndata_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = dectree.predict(X_pred)\n",
    "y_pred\n",
    "\n",
    "# Summarize the Actuals and Predictions\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredType\"], index = pkmndata_pred.index)\n",
    "pkmndata_acc = pd.concat([pkmndata_pred[[\"Name\", \"Type 1\"]], y_pred], axis = 1)\n",
    "\n",
    "pkmndata_acc\n",
    "\n",
    "# Predict Probabilities corresponding to Predictors\n",
    "y_prob = dectree.predict_proba(X_pred)\n",
    "np.set_printoptions(precision = 3)\n",
    "print(y_prob)\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
